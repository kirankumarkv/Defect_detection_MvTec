{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "742ac324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bbfda6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "carpet_root = 'D:/MvTec/mvtec_anomaly_detection/capsule'  \n",
    "\n",
    "test_dir = os.path.join(carpet_root, 'test')\n",
    "train_dir = os.path.join(carpet_root, 'train')\n",
    "ground_truth_dir = os.path.join(carpet_root, 'ground_truth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43d06410",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# transformation images and convert to tensors\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe5bda8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the test dataset\n",
    "test_dataset = ImageFolder(test_dir, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load the train dataset\n",
    "train_dataset = ImageFolder(train_dir, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Load the ground truth dataset\n",
    "ground_truth_dataset = ImageFolder(ground_truth_dir, transform=transform)\n",
    "ground_truth_loader = torch.utils.data.DataLoader(ground_truth_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae803499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the defect labels\n",
    "defect_labels = ['crack', 'faulty_imprint', 'poke', 'scratch', 'squeeze']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b24d6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "defect_attributes = {\n",
    "    'crack': ['visible', 'thin', 'narrow'],\n",
    "    'faulty_imprint': ['misaligned', 'distorted', 'uneven'],\n",
    "    'poke': ['deep', 'sharp', 'small'],\n",
    "    'scratch': ['visible', 'linear', 'surface'],\n",
    "    'squeeze': ['deformed', 'compressed', 'misshapen']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a5eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables for counting correct predictions\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "correct_predictions_by_defect = {label: 0 for label in defect_labels}\n",
    "total_samples_by_defect = {label: 0 for label in defect_labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e814af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_classifier(attributes):\n",
    "    # Define the attribute-based classification rules\n",
    "    if 'visible' in attributes:\n",
    "        return 'good'\n",
    "    elif 'thin' in attributes and 'long' in attributes and 'narrow' in attributes:\n",
    "        return 'crack'\n",
    "    elif 'irregular' in attributes and 'misaligned' in attributes and 'distorted' in attributes:\n",
    "        return 'faulty_imprint'\n",
    "    elif 'deep' in attributes and 'sharp'in attributes and 'small' in attributes:\n",
    "        return 'poke'\n",
    "    elif 'visible' in attributes and 'linear' in attributes and 'surface' in attributes:\n",
    "        return 'scratch'\n",
    "    elif 'deformed' in attributes and  'compressed' in attributes and  'misshapen' in attributes:\n",
    "        return 'squeeze'\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "240d6403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.4574\n",
      "Epoch [2/10], Loss: 0.0000\n",
      "Epoch [3/10], Loss: 0.0000\n",
      "Epoch [4/10], Loss: 0.0000\n",
      "Epoch [5/10], Loss: 0.0000\n",
      "Epoch [6/10], Loss: 0.0000\n",
      "Epoch [7/10], Loss: 0.0000\n",
      "Epoch [8/10], Loss: 0.0000\n",
      "Epoch [9/10], Loss: 0.0000\n",
      "Epoch [10/10], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "class ZeroShotDefectClassifier(nn.Module):\n",
    "    def __init__(self, num_attributes, num_classes):\n",
    "        super(ZeroShotDefectClassifier, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # feature extraction layers\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((4, 4))  # Adjust output size\n",
    "        self.classifier = nn.Linear(256 * 4 * 4, num_attributes)  # Adjust input size\n",
    "        self.fc = nn.Linear(num_attributes, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Model Parameters\n",
    "num_attributes = 10  \n",
    "num_classes = 6  \n",
    "model = ZeroShotDefectClassifier(num_attributes, num_classes)\n",
    "\n",
    "# Save Model\n",
    "torch.save(model.state_dict(), \"model_weights.pth\")\n",
    "\n",
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate the loss\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Print the average loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e21afd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6325\n"
     ]
    }
   ],
   "source": [
    "# Convert predicted labels to numeric indices\n",
    "defect_label_map = {'good': 0, 'crack': 1, 'faulty_imprint': 2, 'poke': 3, 'scratch': 4, 'squeeze': 5, 'unknown': 6}\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize variables for evaluation\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "# Iterate over the test data and labels\n",
    "for images, labels in test_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Perform attribute-based classification\n",
    "    predicted_labels = []\n",
    "    for attributes in defect_attributes.values():\n",
    "        predicted_label = attribute_classifier(attributes)\n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "    predicted_labels_indices = [defect_label_map[label] for label in predicted_labels]\n",
    "    predicted_labels_tensor = torch.tensor(predicted_labels_indices).to(device)\n",
    "\n",
    "    # one-hot encoded \n",
    "    predicted_labels_onehot = torch.nn.functional.one_hot(predicted_labels_tensor, num_classes=len(defect_label_map)).float()\n",
    "\n",
    "    # Update the evaluation metrics\n",
    "    correct_predictions += torch.sum(torch.argmax(predicted_labels_onehot, dim=1) == labels.unsqueeze(1)).item()\n",
    "    total_samples += labels.size(0)\n",
    "\n",
    "accuracy = correct_predictions / total_samples\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a795b714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
